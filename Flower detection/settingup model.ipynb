{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\torch_framework\\.venv\\lib\\site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in e:\\torch_framework\\.venv\\lib\\site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio in e:\\torch_framework\\.venv\\lib\\site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in e:\\torch_framework\\.venv\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\torch_framework\\.venv\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in e:\\torch_framework\\.venv\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in e:\\torch_framework\\.venv\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\torch_framework\\.venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in e:\\torch_framework\\.venv\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in e:\\torch_framework\\.venv\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\torch_framework\\.venv\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/e2/1d/fa6bc3c344cb75f1dd90d6ef188b186c6fd587672323968c89badd562aad/ultralytics-8.0.145-py3-none-any.whl.metadata\n",
      "  Downloading ultralytics-8.0.145-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (4.8.0.74)\n",
      "Requirement already satisfied: pillow>=7.1.2 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (9.3.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Obtaining dependency information for pyyaml>=5.3.1 from https://files.pythonhosted.org/packages/b3/34/65bb4b2d7908044963ebf614fe0fdb080773fc7030d7e39c8d3eddcd4257/PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (0.15.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ---------------------------------------- 0.0/293.3 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 30.7/293.3 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 153.6/293.3 kB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 194.6/293.3 kB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 194.6/293.3 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 293.3/293.3 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in e:\\torch_framework\\.venv\\lib\\site-packages (from ultralytics) (5.9.5)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\torch_framework\\.venv\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\torch_framework\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: filelock in e:\\torch_framework\\.venv\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\torch_framework\\.venv\\lib\\site-packages (from torch>=1.7.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: sympy in e:\\torch_framework\\.venv\\lib\\site-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in e:\\torch_framework\\.venv\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\torch_framework\\.venv\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: colorama in e:\\torch_framework\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in e:\\torch_framework\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\torch_framework\\.venv\\lib\\site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\torch_framework\\.venv\\lib\\site-packages (from sympy->torch>=1.7.0->ultralytics) (1.2.1)\n",
      "Downloading ultralytics-8.0.145-py3-none-any.whl (605 kB)\n",
      "   ---------------------------------------- 0.0/605.6 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 204.8/605.6 kB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 501.8/605.6 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 605.6/605.6 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB 8.4 MB/s eta 0:00:00\n",
      "Installing collected packages: py-cpuinfo, pyyaml, seaborn, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 pyyaml-6.0.1 seaborn-0.12.2 ultralytics-8.0.145\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Current GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(0)  # Use GPU device 0 (change the number accordingly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mhyp\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f8e37439-b1e0-487a-837f-3e85e282c2c0\"', '--shell=9002', '--transport=\"tcp\"', '--iopub=9004', '--f=\"c:\\\\Users\\\\Yedukrishnan S\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-20148B2FJQR0rpSwF.json\"']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32me:\\torch_framework\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3508\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[4], line 19\u001b[0m\n    results = model.train(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\torch_framework\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:372\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self.trainer = trainer(overrides=overrides, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\torch_framework\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:82\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\torch_framework\\.venv\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:113\u001b[0m in \u001b[0;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32me:\\torch_framework\\.venv\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:184\u001b[1;36m in \u001b[1;35mcheck_dict_alignment\u001b[1;36m\n\u001b[1;33m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '\u001b[31m\u001b[1mhyp\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f8e37439-b1e0-487a-837f-3e85e282c2c0\"', '--shell=9002', '--transport=\"tcp\"', '--iopub=9004', '--f=\"c:\\\\Users\\\\Yedukrishnan S\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-20148B2FJQR0rpSwF.json\"']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ('detect', 'segment', 'classify', 'pose')\n                MODE (required) is one of ('train', 'val', 'predict', 'export', 'track', 'benchmark')\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Check CUDA availability and set the GPU device (optional)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)  # Use GPU device 0 (change the number accordingly)\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model\n",
    "\n",
    "# Adjust training settings based on available resources\n",
    "batch_size = 4  # Reduce batch size to fit into 4GB VRAM\n",
    "image_size = 416  # Reduce image size to save VRAM (e.g., 416x416)\n",
    "\n",
    "# Use mixed-precision training for reduced memory usage\n",
    "mixed_precision = True\n",
    "\n",
    "# Training with the specified settings\n",
    "results = model.train(\n",
    "    data=\"config.yaml\",\n",
    "    epochs=25,\n",
    "    batch=batch_size,  # Use 'batch' instead of 'batch_size'\n",
    "    imgsz=image_size,\n",
    "    hyp=\"hyp.yaml\",  # Path to a YAML file containing hyperparameters (if needed)\n",
    "    device=\"cuda\",  # Specify the device here (alternative to setting CUDA device manually)\n",
    "    project=\"your_project_name\",  # Optional project name for saving logs and outputs\n",
    "    name=\"your_run_name\",  # Optional name for this specific run\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
